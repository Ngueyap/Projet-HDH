{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrtUmqPTsRr4SIHce6O783",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ngueyap/Projet-HDH/blob/main/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZkufDyLsh1lK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2078e8bd-f69d-41f5-c81d-f12951736d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-aac2afef74b1>:14: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
            "  Base = declarative_base()\n"
          ]
        }
      ],
      "source": [
        "# Importer les bibliothèques nécessaires\n",
        "from sqlalchemy import create_engine, Column, Integer, String, text, update, select\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "\n",
        "# Créer une instance du moteur SQL\n",
        "engine = create_engine('sqlite:///sante_data.db')\n",
        "\n",
        "# Créer une session SQLAlchemy\n",
        "Session = sessionmaker(bind=engine)\n",
        "session = Session()\n",
        "\n",
        "# Créer une classe de base pour les objets de la base de données\n",
        "Base = declarative_base()\n",
        "\n",
        "\n",
        "# Définir la classe pour la table \"person\"\n",
        "class Person(Base):\n",
        "    __tablename__ = 'person'\n",
        "\n",
        "    person_id = Column(Integer, primary_key=True)\n",
        "    person_source_value = Column(String)\n",
        "    gender_concept_id = Column(Integer)\n",
        "    year_of_birth = Column(Integer)  # Cette colonne sera remplie ultérieurement\n",
        "\n",
        "# Créer la table dans la base de données\n",
        "Base.metadata.create_all(engine)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "class DataCleaner:\n",
        "    def __init__(self, file_path, delimiter):\n",
        "        self.data = pd.read_csv(file_path, sep=delimiter)\n",
        "\n",
        "    def get_num_rows_before_cleaning(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def remove_duplicates(self):\n",
        "        self.data = self.data.drop_duplicates()\n",
        "\n",
        "    def remove_missing_values(self):\n",
        "        self.data = self.data.dropna()\n",
        "\n",
        "    def get_cleaned_data(self):\n",
        "        return self.data\n",
        "\n",
        "    def get_distri_sexe(self):\n",
        "        return self.data['COD_SEX'].value_counts()\n",
        "\n",
        "    def map_sex_codes(self):\n",
        "        # Remplacez les valeurs de COD_SEX selon votre codification\n",
        "        sex_mapping = {1: 'Homme', 2: 'Femme', 0: 'Indéterminé', 9: 'Indéterminé'}\n",
        "        self.data['COD_SEX'] = self.data['COD_SEX'].map(sex_mapping)\n",
        "\n",
        "\n",
        "\n",
        "# Utilisation de la classe pour nettoyer deux fichiers CSV\n",
        "if __name__ == '__main__':\n",
        "    file_path1 = 'T_MCOaaC.csv'\n",
        "    file_path2 = 'T_MCOaaB.csv'\n",
        "\n",
        "    # Définisser le délimiteur pour chaque fichier\n",
        "    delimiter2 = ','  # Délimiteur pour le premier fichier\n",
        "    delimiter1 = '|'  # Délimiteur pour le second fichier\n",
        "\n",
        "    # Créer les instances de DataCleaner en spécifiant les délimiteurs\n",
        "    cleaner1 = DataCleaner(file_path1, delimiter1)\n",
        "    cleaner2 = DataCleaner(file_path2, delimiter2)\n",
        "    num_rows_before_cleaning1 = cleaner1.get_num_rows_before_cleaning()\n",
        "    cleaner1.remove_duplicates()\n",
        "    cleaner1.remove_missing_values()\n",
        "    cleaned_data1 = cleaner1.get_cleaned_data()\n",
        "\n",
        "\n",
        "\n",
        "    num_rows_before_cleaning2 = cleaner2.get_num_rows_before_cleaning()\n",
        "    cleaner2.remove_duplicates()\n",
        "    cleaner2.remove_missing_values()\n",
        "    cleaned_data2 = cleaner2.get_cleaned_data()\n",
        "\n",
        "    # Traitement de la colonne COD_SEX\n",
        "    cleaner2.map_sex_codes()\n",
        "\n",
        "\n",
        "    # nombres de lignes\n",
        "    print(f\"Nombre de lignes avant le nettoyage pour le fichier 1 : {num_rows_before_cleaning1}, \"\n",
        "          f\"Nombre de lignes après le nettoyage : {len(cleaned_data1)}\")\n",
        "    print(f\"Nombre de lignes avant le nettoyage pour le fichier 2 : {num_rows_before_cleaning2}, \"\n",
        "          f\"Nombre de lignes après le nettoyage : {len(cleaned_data2)}\")\n",
        "    print(\"Distribution homme/femme dans T_MCOAAB :\\n\", cleaner2.get_distri_sexe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHPJ6AF_q6WU",
        "outputId": "4afc0252-864d-403f-e049-b1f4c8ac59c5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre de lignes avant le nettoyage pour le fichier 1 : 542, Nombre de lignes après le nettoyage : 514\n",
            "Nombre de lignes avant le nettoyage pour le fichier 2 : 520, Nombre de lignes après le nettoyage : 513\n",
            "Distribution homme/femme dans T_MCOAAB :\n",
            " Femme          190\n",
            "Homme          165\n",
            "Indéterminé    158\n",
            "Name: COD_SEX, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insérer les valeurs de la colonne NIR_ANO_17 dans la table person\n",
        "for index, row in cleaned_data1.iterrows():\n",
        "    nir_ano_17 = row['NIR_ANO_17']\n",
        "\n",
        "    # Créer une nouvelle instance de Person pour chaque valeur NIR_ANO_17\n",
        "    person = Person(person_source_value=nir_ano_17)\n",
        "\n",
        "    # Ajouter cette instance à la session\n",
        "    session.add(person)\n",
        "\n",
        "# Valider les insertions\n",
        "session.commit()"
      ],
      "metadata": {
        "id": "W4xaR6j4ysv9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Effectuer la jointure entre les DataFrames T_MCOAAC et T_MCOAAB en utilisant les clés de jointure ETA_NUM et RSA_NUM\n",
        "merged_data = pd.merge(cleaned_data1, cleaned_data2, on=['ETA_NUM'], how='inner')\n",
        "# Définisser le mapping entre les valeurs de sexe SNDS classique et OMOP-CDM\n",
        "sex_mapping = {\n",
        "    'Homme': 8507,  # Homme selon OMOP-CDM\n",
        "    'Femme': 8532,  # Femme selon OMOP-CDM\n",
        "    # Ajoutez d'autres mappages si nécessaire\n",
        "}\n",
        "# Appliquer le mapping et mettez à jour la colonne gender_concept_id dans la table person\n",
        "for index, row in merged_data.iterrows():\n",
        "    NIR_ANO_17 = row['NIR_ANO_17']\n",
        "    sexe_snds = row['COD_SEX']\n",
        "\n",
        "    # Vérifier si le sexe SNDS classique est défini\n",
        "    if sexe_snds in sex_mapping:\n",
        "        # Metter à jour la colonne gender_concept_id\n",
        "        session.query(Person).filter(Person.person_source_value == NIR_ANO_17).update({\"gender_concept_id\": sex_mapping[sexe_snds]})\n",
        "\n",
        "# Enlever les patients pour qui le sexe n'est pas défini dans le SNDS classique\n",
        "session.query(Person).filter(Person.gender_concept_id.is_(None)).delete()\n",
        "session.commit()"
      ],
      "metadata": {
        "id": "vb1Pej83FWoZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supprimer les doublons sur la colonne person_source_value\n",
        "query = text('''\n",
        "    Delete FROM person\n",
        "    WHERE person_id NOT IN (\n",
        "        SELECT MIN(person_id)\n",
        "        FROM person\n",
        "        GROUP BY person_source_value\n",
        "        HAVING COUNT(*) > 1\n",
        "    )\n",
        "''')\n",
        "session.execute(query)\n",
        "session.commit\n",
        "\n",
        "# Mettre à jour la colonne Person_id\n",
        "# SélectionneR tous les enregistrements triés par 'person_id' de manière ascendante\n",
        "records = session.query(Person).order_by(Person.person_id).all()\n",
        "\n",
        "# Nouvel ID initial\n",
        "new_id = 1\n",
        "\n",
        "# ParcourIR les enregistrements et attribuez un nouvel ID séquentiel à chaque enregistrement\n",
        "for record in records:\n",
        "    # Mettez à jour 'person_id' avec le nouvel ID\n",
        "    record.person_id = new_id\n",
        "    new_id += 1\n",
        "\n",
        "\n",
        "session.commit()"
      ],
      "metadata": {
        "id": "IbvbUhIuldoR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METTRE 'EXE_SOI_DTD' est déjà au format datetime\n",
        "merged_data['EXE_SOI_DTD']= pd.to_datetime(merged_data['EXE_SOI_DTD'], format='%d%b%Y:%H:%M:%S')\n",
        "\n",
        "# cALCUL DE L'age\n",
        "from dateutil.relativedelta import relativedelta\n",
        "merged_data['birth_date']= merged_data['EXE_SOI_DTD'].dt.date-merged_data['AGE_ANN'].apply(lambda y: relativedelta(years=y))\n",
        "\n",
        "for index, row in merged_data.iterrows():\n",
        "    person_source_value = row['NIR_ANO_17']\n",
        "    birth_date = row['birth_date']\n",
        "    # Créez une instruction de mise à jour\n",
        "    update_statement = update(Person).where(Person.person_source_value == person_source_value).values(year_of_birth=birth_date)\n",
        "\n",
        "    # Exécutez la mise à jour\n",
        "    session.execute(update_statement)\n",
        "\n",
        "session.commit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0V4bi_G0eCH",
        "outputId": "bbf2a348-f594-429d-ad96-acc9a43854e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Session.commit of <sqlalchemy.orm.session.Session object at 0x7abfa5b57c70>>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = text('select *  from person')\n",
        "\n",
        "\n",
        "# Exécuter la requête SELECT en utilisant la session\n",
        "duplicates = session.execute(query)\n",
        "\n",
        "# ParcourIR les résultats pour obtenir les doublons\n",
        "for row in duplicates:\n",
        "    print(row.person_id, row.person_source_value, row.year_of_birth)\n",
        "\n"
      ],
      "metadata": {
        "id": "msGKx7S3H-m2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ac12509-0f7e-402c-aef0-fdeb5867143b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 fiosftusfZACfuNhE 1919-07-10\n",
            "2 pTzHiYhikHWhkIIKu 1951-06-13\n",
            "3 lfQvrRwJWWSwgKiKh 1920-12-16\n",
            "4 LqgAzcvGjjokflOzN 1913-12-08\n",
            "5 fUjvhXqgHxhzIcZUV 1926-01-18\n",
            "6 MmWEyevQtWEtwYnZT 1880-11-15\n",
            "7 HxbMiGPkIcNbbxgHD 1887-10-05\n",
            "8 iFoRwhprfLBIyxCxO 1904-03-10\n",
            "9 EWsJuBZVXYjPjGHuv 1889-02-21\n",
            "10 OjkjMtKgaNWGzgMBt 1910-09-04\n",
            "11 KFaQejdWYHUTDkpcD 1958-05-10\n",
            "12 WYJjxkqwmqOmlRdTW 1967-04-08\n",
            "13 SWiIFwXRNFkwXWuHz 1952-03-31\n",
            "14 NZKwdbuWNoyNyfynT 1954-06-28\n",
            "15 BRDIBOcmZaFRfgyxP 1868-04-08\n",
            "16 jlxHDqxUWgGtMkCeW 1963-06-28\n",
            "17 JoOvWOTlkKmqsdQli 1923-07-05\n",
            "18 SmhgNiVqEmYaXzhdI 1894-01-20\n",
            "19 lYQcBYGQSYPGjebQB 1907-08-04\n",
            "20 kZdpxMDzRRWmUQCkb 1991-01-14\n",
            "21 mXDLkVKtmCVkhIYkg 1946-12-03\n",
            "22 eZpnYdlIFKOdvrSoR 2009-11-18\n",
            "23 ZdYOEoBxluCntBWVs 1959-07-10\n",
            "24 OmGnVKNDBzcowsYnz 1892-03-05\n",
            "25 KpEPISHilApknOjPk 1990-04-14\n",
            "26 WsggWmVVSzfWAPKhI 1949-04-26\n",
            "27 dmRbBIcUFxtHkYzsh 1921-06-27\n",
            "28 HpXqlxqQbuGvwsWTS 1962-12-02\n",
            "29 vLZEkshVzlwcVoCMU 1979-05-02\n",
            "30 ndYlKJPZfyIOCwdnw 1921-11-03\n",
            "31 TkguxtzmvNMrIaRiK 1973-05-29\n",
            "32 uaceYfxqOyuQEbwyb 1952-03-28\n",
            "33 ODgokXDMIiqIfhNyD 1938-03-20\n",
            "34 vKPeTPLjheppRwCzR 1889-03-23\n",
            "35 BOVHszVYePPTeDTib 1959-07-13\n",
            "36 scUzHDrMwIYYkRXGt 1988-06-09\n",
            "37 ruAHhHndYdpqlxBys 1907-05-25\n",
            "38 dSkgxkAUjOYIEcuzL 1916-02-22\n",
            "39 LkxBOCHprUtqySAEv 1944-03-23\n",
            "40 HYhgjxUfljXMNNLRF 1919-01-26\n",
            "41 vOdcyEdhBVIvrtocZ 1877-01-29\n",
            "42 WyTjCqGMEIOIepsHC 1942-12-17\n",
            "43 DjdJptXowFmeVfGSV 1946-11-20\n",
            "44 xUHyrfjXbevYPEGLk 1987-09-13\n",
            "45 qfSRRppwKiEVjwvck 1972-02-19\n",
            "46 gsXFfQhOYnudWgyQO 1962-10-28\n",
            "47 ZqlxedSSgRjHnmSpH 1888-10-13\n",
            "48 QKKRDWyLJjrGUyGZE 1948-12-29\n",
            "49 xEJgxLwxnPlyrhnCu 1867-12-04\n",
            "50 ckbEmpuxdjDltVKjf 1943-06-30\n",
            "51 mRNEGKLWkjpxKJZqi 1926-11-18\n",
            "52 LjpboGzJhyFpMRfJc 1878-05-02\n",
            "53 hturmbCsAfCRmgRPA 1980-03-18\n",
            "54 gFCcAnNDhUkbXoGFa 1980-05-27\n",
            "55 wBexkitsRjmsSfswE 1959-07-14\n",
            "56 dPdnRephLcoqNxioz 1860-04-22\n",
            "57 ngvOAMnzhslDcXIRc 1877-05-19\n",
            "58 judYpyqUDfyAzDsYJ 1939-09-25\n",
            "59 ZEkKMBQCQfuwhBtfX 1883-06-01\n",
            "60 gGcaEMdhIFhLfYJCK 1969-03-19\n",
            "61 wHSaVGOrtYGcyUJKI 1997-03-07\n",
            "62 AXzSFlFqIemCAVgzz 1987-06-20\n",
            "63 gRkwvVWPrvvmiUBZz 1973-11-01\n",
            "64 bKIxIdFOzWIBiWLRe 1894-05-27\n",
            "65 ESsVdyqsKTcGfNJey 1941-11-30\n",
            "66 DLtTOSJnHzPqZLRKP 1890-04-09\n",
            "67 omNScTJomStFQcZLO 1938-04-22\n",
            "68 fHClWcxyOycaBLLde 1924-06-26\n",
            "69 JBeeNwSzMBuFctZDO 1945-07-02\n",
            "70 lJIQUKWciXzjLHvCQ 1882-07-03\n",
            "71 YMnFBJHphFRLAqSIe 1946-12-29\n",
            "72 dkmpIzEmSkVLgnWHr 1881-01-25\n",
            "73 OWdhhmNmKOXVudJLC 1887-06-21\n",
            "74 KhAmEBTuhyFkGeDSB 1905-01-02\n",
            "75 CRByuOzqdhFWMVQaW 1928-08-21\n",
            "76 IwccymFqBVyKlEOrB 1971-12-14\n",
            "77 YAsYDAasVFktoqOFo 2005-02-03\n",
            "78 xpekoRTrEKpGWJVIZ 1980-06-10\n",
            "79 DKBPcAhUdoVGUFkjD 1916-07-02\n",
            "80 VjBnEeycVwfDQGGyh 1979-05-22\n",
            "81 MFBHeLtaROOuTYUdd 1985-12-20\n",
            "82 LiTxtAwiImnUSsBnC 1877-02-10\n",
            "83 arznmsUSOJOxITYCx 1971-07-09\n",
            "84 LwcqamdrWSlpwDrer 1930-10-06\n",
            "85 WvcYrkGqyLCdxmbBK 1935-07-03\n",
            "86 OhGKSSmogbBwLOpDZ 1976-08-27\n",
            "87 MrCFNoHNdvAyirtjM 1946-01-24\n",
            "88 xllHLbfuGaAjEBFSH 1885-06-05\n"
          ]
        }
      ]
    }
  ]
}